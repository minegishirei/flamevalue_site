from .careerJet import clear_jnet,mock_getCareerJet, row_converter, getCareerJet
from .wikipedia_list import get_wikipedia_list
from .JsonIO import JsonDictionalyManager, JsonIO
from .my_tools import del_dub_dict_list
from django.shortcuts import render, redirect, HttpResponse
import json
import sys
if '/God' not in sys.path:
    sys.path.append('/God')
#import Github
from .my_Admin_Markdown import getAdminMarkdown
from .my_mecab import getMeishiList
from .my_Qiita import getQiitaInfo
from .my_Qiita import getQiitaTags
from .my_Qiita import putQiitaArticle
from .my_SQLite_FlamevalueControl import SQLiteFlamevalueControl
from .my_SQLite_LoginControl import SQLiteLoginControl
from .my_SQLite_UserInfoControl import UserInfoCollector
from .my_SQLite_Profile import SQLiteProfileImage

# .dbãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ–
SQLiteFlamevalueControl().end()
SQLiteLoginControl().end()
UserInfoCollector().end()
SQLiteProfileImage().end()

from functools import reduce
from operator import add
import datetime
import pprint
import wikipedia
# è¨€èªã‚’æ—¥æœ¬èªã«è¨­å®š
wikipedia.set_lang("jp")
from .my_tools import calc_distance
from multiprocessing import Process
import random
import math            

jsonDictionalyManager = JsonDictionalyManager()
FLAMEWORKDICT = jsonDictionalyManager.generate_all_flameworkdict()
COMPARE_STAGE_LIST = set()


def grep(column):
    def no_name(row):
        return row[column]
    return no_name
def average_data(origin, column):
    grep_column = grep(column)
    return reduce(lambda value, i_dict: value + grep_column(i_dict), origin, 0)/len(origin)


def basic(origin):
    if len(origin) < 1:
        return {
            "money" : 0,
            "overtime" : 0,
            "age" : 0,
            "count" : 0,
            "size" : 0
        }
    return {
        "money" : round(average_data(origin, "å¹´å")),
        "overtime" : round(average_data(origin, "æ®‹æ¥­æ™‚é–“")),
        "age" : round(average_data(origin, "å¹´é½¢")),
        "size" : round(average_data(origin, "è¦æ¨¡")),
        "remote" : round(average_data(origin, "ãƒªãƒ¢ãƒ¼ãƒˆç‡")),
        "count" : len(origin)
    }

def TEST_average_data():
    expect = 470
    actual = basic(origin)["money"]
    assert expect == actual , f"error : test_average_data expected : {expect}, actual: {actual}" 
    

def scoring_cuury(score):
    def inside_cuury(basic_dict):
        return {key: score(key, value) for key, value in basic_dict.items()}
    return inside_cuury

def score_currey(max_score, max_values):
    def score(key,value):
        result =  (value/max_values[key])*max_score 
        if result > max_score:
            return max_score
        else:
            return result
    return score

max_values = {
    "money" : 700,
    "overtime" : 1000,
    "age" : 60,
    "count" : 10000,
    "size" : 1000,
    "remote" : 70,
    "qiita_score" : 20000,
}
score       = score_currey(5, max_values)
score_100   = score_currey(100, max_values)

scoring = scoring_cuury(score)
scoring_100 = scoring_cuury(score_100)
def TEST_scoring():
    expect = 30
    result = scoring(basic(origin))
    actual = result["money"]
    assert  actual < expect , f"error : test_average_data expected : {expect}, actual: {actual}, result {result}" 


def split_timetable(origin):
    sorted_origin = sorted(origin, key=lambda row:datetime.datetime.strptime(row["æ—¥ä»˜"], '%Y-%m-%d'))
    date_list = [datetime.datetime.now() + datetime.timedelta(days=i) for i in range(-3,-60,-3)]
    return_timetable = [{ "date": i.strftime("%Y-%m-%d"), "origin":[]} for i in date_list]
    for i_job in sorted_origin:
        for i, i_date in enumerate(date_list):
            date1 = datetime.datetime.strptime(i_job["æ—¥ä»˜"], '%Y-%m-%d')
            date2 = datetime.datetime.strptime(i_job["æ—¥ä»˜"], '%Y-%m-%d') - datetime.timedelta(days=7)
            if  date2 < i_date and i_date < date1:
                return_timetable[i]["origin"].append(i_job)
    return_timetable = list(reversed(return_timetable))
    return return_timetable
def TEST_split_timetable():
    timetable = split_timetable(origin)
    assert timetable[1], "error : TEST_split_timetable"

"""
TEST_average_data()
TEST_scoring()
TEST_split_timetable()
"""


def get_money_countlist(origin, column, steps = None):
    origin = sorted(origin, key=lambda row:row[column])
    steps = range(0, 1000, 100)
    count_list = [0 for row in steps]
    for row in origin:
        for i, step in enumerate(steps):
            if row[column] < step and step < row[column] + 100:
                count_list[i] += 1
    return count_list


def get_wiki_explain(name):
    words = wikipedia.search(name)
    page = wikipedia.page(words[0], auto_suggest=False)
    return {
        "explain" : "ã€‚".join(page.summary.split("ã€‚")[:4]),
        "comments" : (page.summary.split("ã€‚")[4:7]),
        "image" : page.images[0]
    }


def get_qiita_comments(name, word):
    def get_good_comment(name, markdown):
        hit_word = re.findall(name+'.?' + word, markdown)[0]
        text1 =  hit_word + "\n" + hit_word.join( markdown.split(hit_word)[1:] )
        text2 = text1[:500]
        new_tag = '#### '
        text2 = re.sub('#+', new_tag, text2)
        text3 = new_tag + "\n" + new_tag.join( text2.split(new_tag)[:1] )
        return text3
    feature_include_list = filter( lambda x: re.findall(name+'.?'+word, x["body"]),getQiitaInfo("title:"+name+word, 100) )
    qiita_comments = []
    for row in feature_include_list:
        target_text = row["body"]
        new_text = get_good_comment(name, target_text)
        row.update({
            "body" : new_text,
            "origin_body" : row["body"],
            "rendered_body" : ""
        })
        if len(new_text) > 100:
            qiita_comments.append(row)
    return qiita_comments




import re
def build_param(name_original):
    name = name_original
    origin = getCareerJet(name.replace("(ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª)", ""))
    jobs = origin["jobs"]
    hits = origin["hits"]
    origin = row_converter(clear_jnet(jobs))
    basic_info = basic(origin)
    qiita_info = getQiitaInfo(name, 100)
    basic_info.update({
        "count" : hits,
        #"qiita_score" : reduce(lambda a, b: a + int(b["user"]["followees_count"]), qiita_info, 0) / len(qiita_info)
    })
    qiita_tags = getQiitaTags(name.replace("è¨€èª",""))
    basic_info.update({
        "qiita_score" : qiita_tags["followers_count"]
    })
    total_score = round( sum(scoring(basic_info).values())/len(scoring(basic_info)), 2)
    total_score_int = int(round(total_score) )
    data_param = {
        "name" : name,
        "explain" : "Djangoï¼ˆã‚¸ãƒ£ãƒ³ã‚´ï¼‰ã¯ã€Pythonã§å®Ÿè£…ã•ã‚ŒãŸWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"
    }
    print(data_param)

    wordcount_list =  getMeishiList("ã€‚".join([row["description"] for row in jobs]))
    data_param.update({
        "date" : datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'),
        "total_score" :  total_score,
        "stars" : "â˜…"*total_score_int + "â˜†"*(5-total_score_int),
        "basic" : basic_info,
        "score" : scoring(basic_info),
        "score_100" : scoring_100(basic_info),
        "basic_graph" : [ {row["date"]: basic(row["origin"])} for row in split_timetable(origin) ],
        "score_graph" : [ {row["date"]: scoring(basic(row["origin"]))} for row in split_timetable(origin) ],
        "score_graph_json" : json.dumps([ {"date": row["date"], "values" : scoring(basic(row["origin"]))} for row in split_timetable(origin) ]),
        "money_sorted" : sorted(origin, key=lambda row:row["å¹´å"]),
        "jobs" : clear_jnet(jobs),
        "min_salary" : sorted( clear_jnet(jobs), key=lambda row:row["salary_min"]),
        "wordcloud_json" : json.dumps(wordcount_list, ensure_ascii=False ),
        "money_countlist" : json.dumps( {'lower' : get_money_countlist(origin, "å¹´å"), 'upper' : get_money_countlist(origin, "æ®‹æ¥­æ™‚é–“")} ),
        "qiita_acounts" : sorted( del_dub_dict_list([ row["user"] for row in getQiitaInfo(name, 100) ]) , key=lambda x: x["items_count"], reverse=True )[:5],
        "qiita_comments" : get_qiita_comments(name, "ãƒ¡ãƒªãƒƒãƒˆ") + get_qiita_comments(name, "ç‰¹å¾´")+ get_qiita_comments(name, "ã¨ã¯")
        # Administratorç”¨ã®ã‚³ãƒ¡ãƒ³ãƒˆ
        #"admin_comment" : getAdminMarkdown(name),
        # æœ¬å½“ã¯ã“ã“ã«æ›¸ããŸã„ãŒã€Goodã‚’æŠ¼ã—ãŸå¾Œã®æ™‚å·®ã®é–¢ä¿‚ã§å¾Œã»ã©update
        #"goodness_count" : SQLiteFlamevalueControl().get_goodness_count(flamework_name = name)[0][0]
    })
    html_param = {
        "title" : f"{name} ã€Œå¹´å/æ¡ç”¨ä¼æ¥­ã€ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è»¢è·è©•ä¾¡ FlameValue",
        "description" : f"{name}ã®ã€Œå¹´å/æ¡ç”¨ä¼æ¥­æƒ…å ±ã€ã€‚å°±è·ãƒ»è»¢è·å‰ã«{name}ã®åƒãç’°å¢ƒã€å¹´åãƒ»æ±‚äººæ•°ãªã©ã‚’ãƒªã‚µãƒ¼ãƒã€‚å°±è·ãƒ»è»¢è·ã®ãŸã‚ã®ã€Œ{name}ã€ã®ä¾¡å€¤åˆ†æãƒãƒ£ãƒ¼ãƒˆã€æ±‚äººæƒ…å ±ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æ²è¼‰ã€‚"
    }
    print(data_param)

    wikipedia_param = get_wiki_explain(name_original+"(IT)")
    related_word = [ row_v2["word"] for row_v2 in wordcount_list]
    wikipedia_related = {"wikipedia_related": list(filter(lambda row : (row["name"] in related_word) , FLAMEWORKDICT) )}

    comments = []
    try:
        FLAMEVALUE_DATABASE_REPO = "flamevalue_database"
        category = f"comments/{name}"
        for htmlname in Github.seach_page_list(FLAMEVALUE_DATABASE_REPO, category):
            row_json = Github.load(FLAMEVALUE_DATABASE_REPO, category + "/" +htmlname)
            comments.append( json.loads(row_json) )
    except:
        pass

    param = {}
    comments_param = {
        "user_comments" : comments
    }
    param.update(comments_param)
    param.update(data_param)
    param.update(html_param)
    param.update(wikipedia_param)
    param.update({
        "image" : qiita_tags["icon_url"]
    })
    param.update(wikipedia_related)
    return param


import random
def titleABTest():
    return random.choice([
        lambda name, description: {
            "title" : f"ã€è»¢è·ã€‘ã€Œ{name}ã®å¹´åã£ã¦å®Ÿéš›ã©ã†ãªã®ï¼Ÿã€ ğŸ‘ˆ",
            "description" : f"{description}"
        },lambda name, description: {
            "title" : f"ã€è»¢è·ã€‘{name}ã®å¹´åã¯é«˜ã„",
            "description" : f"{description}"
        }
    ])

def titleProduction():
    return (lambda name, description: {
        "title" : f"{name}ã¯ã‚ªãƒ¯ã‚³ãƒ³ãªã®ã‹?",
        "description" : f"{description}"
    })



def page(request, htmlname):
    if htmlname == "robots.txt":
        return robots(request)
    
    name = htmlname
    param = {}
    jsonIO = JsonIO()
    param = build_param(name)
    jsonIO.write(param["name"],param)

    
    # Goodã‚’è¿½åŠ æ™‚ã®å‡¦ç†
    if request.GET.get("active-add-good"):
        has_session_logininfo = (request.session.get("e_mail") and request.session.get("hashed_password") )
        is_certification_ok = SQLiteLoginControl().certification_by_hashed_password(request.session.get("e_mail") , request.session.get("hashed_password", ""))
        if (has_session_logininfo) and (is_certification_ok) :
            SQLiteFlamevalueControl().add_one_good(request.session["e_mail"], htmlname)
        else:
            return redirect("/login.html")
    # Goodã‚«ã‚¦ãƒ³ãƒˆã‚’å³æ™‚åæ˜ ã•ã›ã‚‹ãŸã‚ã®å‡¦ç†
    param.update({
        "goodness_count" : SQLiteFlamevalueControl().get_goodness_count(flamework_name=htmlname)[0][0]
    })
    
    # 5å‰²ã®ç¢ºç‡ã§ãƒšãƒ¼ã‚¸ã‚’å†æ§‹æˆã™ã‚‹
    if True: #random.random() < 0.5:
        reload_subprocess(name)
    
    # ã‚³ãƒ¡ãƒ³ãƒˆã‚„ä»•äº‹ã‚¿ãƒ–ã‚’é–‹ã„ãŸæ™‚ã®å‡¦ç†
    GET_active = request.GET.get("active")
    if GET_active == "jobs":
        param.update({
            "title" : f"{name} æ±‚äººä¸€è¦§",
            "description" : f"{name}ã®æ¡ç”¨æƒ…å ±ã§ã™ã€‚FlameValueã¯{name}ã®æ¡ç”¨æƒ…å ±ãƒ»æ±‚äººæƒ…å ±ã‚’æ²è¼‰ã—ã¦ã„ã¾ã™ã€‚"
        })
    elif GET_active == "comments":
        param.update({
            "title" : f"{name}ã®è©•ä¾¡/è©•åˆ¤",
            "description" : f"{name}ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã®ã‚¯ãƒã‚³ãƒŸãƒ»è©•ä¾¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚{name}ã®æ¡ç”¨ã‚’æ¤œè¨ã•ã‚Œã¦ã„ã‚‹æ–¹ãŒã€{name}ã®ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã‚’æŠŠæ¡ã™ã‚‹ãŸã‚ã®å‚è€ƒæƒ…å ±ã¨ã—ã¦ã€{name}ã‚’ä½¿ç”¨ã—ãŸé–‹ç™ºè€…ã‹ã‚‰ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã«é–¢ã™ã‚‹ã‚¯ãƒã‚³ãƒŸã‚’åé›†ã—æ²è¼‰ã—ã¦ã„ã¾ã™ã€‚å°±è·ãƒ»æ¡ç”¨æ´»å‹•ã§ã®ä¸€æ®µæ·±ã‚ãŸé–‹ç™ºè€…ãƒªã‚µãƒ¼ãƒã«ã”æ´»ç”¨ã„ãŸã ã‘ã¾ã™ã€‚"
        })
    elif GET_active == "post_comment":
        if not judge_certification_ok(request):
            return redirect("/login.html")
        elif request.POST.get("active_post_comment"):
            title               = request.POST.get("title", None)
            markdown_message    = request.POST.get("markdown_message", None)
            if title and markdown_message:
                try:
                    Github.upload("flamevalue_database", f"comments/{name}/0", "")
                except:
                    pass
                Github.upload("flamevalue_database", f"comments/{name}/{title}.json", json.dumps({
                    "username" : request.session.get("username"),
                    "e_mail" : request.session.get("e_mail"),
                    "title" : title,
                    "markdown_message" : markdown_message,
                },
                ensure_ascii=False,
                indent=4))
        param.update({
            "title" : f"{name}ã®å£ã‚³ãƒŸæŠ•ç¨¿",
            "description" : f"{name}ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã®ã‚¯ãƒã‚³ãƒŸãƒ»è©•ä¾¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚{name}ã®æ¡ç”¨ã‚’æ¤œè¨ã•ã‚Œã¦ã„ã‚‹æ–¹ãŒã€{name}ã®ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã‚’æŠŠæ¡ã™ã‚‹ãŸã‚ã®å‚è€ƒæƒ…å ±ã¨ã—ã¦ã€{name}ã‚’ä½¿ç”¨ã—ãŸé–‹ç™ºè€…ã‹ã‚‰ã€Œã™ã¹ã¦ã®é–‹ç™ºè€…ã‚¯ãƒã‚³ãƒŸã€ã«é–¢ã™ã‚‹ã‚¯ãƒã‚³ãƒŸã‚’åé›†ã—æ²è¼‰ã—ã¦ã„ã¾ã™ã€‚å°±è·ãƒ»æ¡ç”¨æ´»å‹•ã§ã®ä¸€æ®µæ·±ã‚ãŸé–‹ç™ºè€…ãƒªã‚µãƒ¼ãƒã«ã”æ´»ç”¨ã„ãŸã ã‘ã¾ã™ã€‚"
        })
    else:        
        param.update(titleProduction()(name,param["explain"].replace("\n","") ))
    
    #url = https://github.com/kawadasatoshi/flamevalue_database/blob/main/comments/
    return render(request, f"jobstatic_pages/page.html", param)


def compare(request):
    color_candidate = [
            '#26B99A', '#34495E',  '#3498DB', '#BDC3C7',
            '#9B59B6', '#8abb6f', '#759c6a', '#bfd3b7'
        ]
    
    candidate_list = request.GET.getlist("candidate")
    if len(candidate_list) <= 1:
        return redirect("/")
    jsonIO = JsonIO()
    compare_result = list(map(lambda name: {
        "param" : jsonIO.read(name),
        "name" : name,
        "color" : color_candidate.pop(0) #"#"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])
    }, filter(lambda name_str: jsonIO.exists(name_str), candidate_list) ))

    def create_one_series(row, key):
        money_countlist = json.loads(row["money_countlist"])
        return {
            "name": row["name"],
            "type": 'bar',
            "data": money_countlist[key],
            "markPoint": {
                "data": [{
                    "type": 'max',
                    "name": '???'
                }]
            },
            "markLine": {
                "data": [{
                    "type": 'average',
                    "name": '???'
                }]
            }
        }
    COMPARE_STAGE_LIST.add(frozenset(candidate_list))
    user_comments = sum( list(map(lambda row:row['param'].get('user_comments',[]) ,compare_result)), [])
    admin_comment = user_comments[0]["markdown_message"] if len(user_comments) > 0 else f"{'ã¨'.join(candidate_list)}ã®é•ã„ã«ã¤ã„ã¦ã¾ã¨ã‚ã¾ã—ãŸã€‚ãƒ„ãƒ¼ãƒ«ã®æŠ€è¡“é¸å®šã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’ã®éš›ã«ã©ã®è¨€èªã‚’é¸æŠã™ã‚‹ã‹ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚"
    param = {
        "compare_result" : compare_result,
        "candidate_list" : candidate_list,
        "wikipedia_related" : compare_result,
        "jobs" :   sum( list(map(lambda row:row['param']['jobs'] ,compare_result)), []),
        "user_comments" :   user_comments,
        "admin_comment" :   admin_comment,
        "title"  :f'ã©ã£ã¡ãŒã„ã„? { " vs ".join(candidate_list)}',
        "description" : f"{'ã¨'.join(candidate_list)}ã®é•ã„ã«ã¤ã„ã¦ã¾ã¨ã‚ã¾ã—ãŸã€‚ãƒ„ãƒ¼ãƒ«ã®æŠ€è¡“é¸å®šã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’ã®éš›ã«ã©ã®è¨€èªã‚’é¸æŠã™ã‚‹ã‹ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚",
        "img" : "https://github.com/kawadasatoshi/minegishirei/blob/main/flamevalue/flamevalue.png?raw=true",
        "name"   :f'å¾¹åº•æ¯”è¼ƒ! { " vs ".join(candidate_list)}',
        "money_list_lower_series" : json.dumps({
            "title": {
                "text": 'ä¸‹æ–¹å¹´å',
                "subtext": 'å˜ä½ï¼šä»¶/ä¸‡å††'
            },
            "tooltip": {
                "trigger": 'axis'
            },
            "legend": {
                "data": candidate_list
            },
            "toolbox": {
                "show": False
            },
            "calculable": False,
            "xAxis": [{
                "type": 'category',
                "data": ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900']
            }],
            "yAxis": [{
                "type": 'value'
            }],
            "series": list(map(lambda row : create_one_series(row["param"], "lower") ,compare_result))
        }, ensure_ascii=False),
        "money_list_upper_series" : json.dumps({
            "title": {
                "text": 'ä¸Šæ–¹å¹´å',
                "subtext": 'å˜ä½ï¼šä»¶/ä¸‡å††'
            },
            "tooltip": {
                "trigger": 'axis'
            },
            "legend": {
                "data": candidate_list
            },
            "toolbox": {
                "show": False
            },
            "calculable": False,
            "xAxis": [{
                "type": 'category',
                "data": ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900']
            }],
            "yAxis": [{
                "type": 'value'
            }],
            "series": list(map(lambda row : create_one_series(row["param"], "upper") ,compare_result))
        }, ensure_ascii=False)
    }
    return render(request, f"jobstatic_pages/compare.html", param)


def ranking(request):
    e_mail = request.session.get("e_mail")
    hashed_password = request.session.get("hashed_password") 
    username = request.session.get("username")
    has_session_info = ("e_mail" in request.session) and ("hashed_password" in request.session)
    is_certification_ok = SQLiteLoginControl().certification_by_hashed_password(request.session.get("e_mail") , request.session.get("hashed_password", ""))
    if has_session_info and (is_certification_ok) :
        pass
    else:
        return redirect("/login.html")
    params = {
        "title" : f"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª å¹´åãƒ©ãƒ³ã‚­ãƒ³ã‚° {datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} æœ€æ–°ç‰ˆ",
        "description" : f"{datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}æ›´æ–° Flamevalue ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å¹´åã”ã¨ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–ã€‚æŠ€è¡“é¸å®šã‚„å­¦ç¿’ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªé¸ã³ã«Flamevalue",
        "img" : "https://github.com/kawadasatoshi/minegishirei/blob/main/flamevalue/flamevalue.png?raw=true"
    }
    params.update({
        "ranking_list" : sorted(FLAMEWORKDICT, key=lambda x: x["basic"]["money"], reverse=True),
    })
    if request.GET.get("active"):
        params.update({
            "ranking_list" : sorted(FLAMEWORKDICT, key=lambda x: x["basic"][request.GET.get("active")], reverse=True)
        })
    
    # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
    #putQiitaArticle("å·¥äº‹ä¸­...",  ,"article", "", True)
    print(build_Qiita_context(FLAMEWORKDICT, sort_function = (lambda x: x["basic"]["money"]) ))

    # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªå¹´åãƒ©ãƒ³ã‚­ãƒ³ã‚°
    if random.random() < 0.5:
        putQiitaArticle(
            title = "ä¸‹æ–¹å¹´åãƒ©ãƒ³ã‚­ãƒ³ã‚°", 
            markdown = build_Qiita_context(FLAMEWORKDICT, sort_function = (lambda x: x["basic"]["money"])) ,
            tags = list(map(lambda row:{"name":row["name"]}, sorted(FLAMEWORKDICT, key=lambda x: x["basic"]["money"]) ))[:5],
            path = "article", 
            id = "011a797391f3e5c7c5d4",
            is_private = False
        )
        
        putQiitaArticle(
            title = "è»¢è·å¸‚å ´ãƒ©ãƒ³ã‚­ãƒ³ã‚°Top15", 
            markdown = build_Qiita_context(FLAMEWORKDICT, sort_function = (lambda x: x["total_score"])) ,
            tags = list(map(lambda row:{"name":row["name"]}, sorted(FLAMEWORKDICT, key=lambda x: x["total_score"]) ))[:5],
            path = "article", 
            id = "c2acb400a27ab78c22b6",
            is_private = False
        )
    return render(request, f"jobstatic_pages/ranking.html", params)


flamevalue_score_ranking_count = 0

def build_Qiita_context(FLAMEWORKDICT, sort_function = ""):
    global flamevalue_score_ranking_count
    flamevalue_score_ranking_count= 0
    def row_context(row):
        def floor(value):
            return math.floor(value * 100) / 100
        global flamevalue_score_ranking_count
        flamevalue_score_ranking_count += 1
        admin_markdown = None
        return f"""
# ç¬¬{flamevalue_score_ranking_count}ä½ : {row["name"]} : {row["stars"]}

ã‚¹ã‚³ã‚¢ : **{row["total_score"]}**/5

| é …ç›®å            | ãƒã‚¤ãƒ³ãƒˆ                             | ãƒã‚¤ãƒ³ãƒˆ(5ç‚¹æº€ç‚¹)                    | å®Ÿç¸¾                            | 
| :---------------- | ------------------------------------ | ------------------------------------ | ------------------------------- | 
| ä¸‹é™å¹´å          | { "â˜…"*(int(floor(row["score"]["money"]))) + "â˜†"*(5-int(floor(row["score"]["money"])) ) }       | {floor(row["score"]["money"])}       | {row["basic"]["money"]}ä¸‡å††     | 
| ä¸Šé™å¹´å          | { "â˜…"*(int(floor(row["score"]["overtime"]))) + "â˜†"*(5-int(floor(row["score"]["overtime"])) ) }    | {floor(row["score"]["overtime"])}    | {row["basic"]["overtime"]}ä¸‡å††  | 
| æ±‚äººæ•°            | { "â˜…"*(int(floor(row["score"]["count"]))) + "â˜†"*(5-int(floor(row["score"]["count"])) ) }        | {floor(row["score"]["count"])}       | {row["basic"]["count"]}ä»¶       | 
| ãƒªãƒ¢ãƒ¼ãƒˆç‡        | { "â˜…"*(int(floor(row["score"]["remote"]))) + "â˜†"*(5-int(floor(row["score"]["remote"])) ) }       | {floor(row["score"]["remote"])}      | {row["basic"]["remote"]}%       | 
| Qiitaãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•° | { "â˜…"*(int(floor(row["score"]["qiita_score"]))) + "â˜†"*(5-int(floor(row["score"]["qiita_score"])) ) }  | {floor(row["score"]["qiita_score"])} | {row["basic"]["qiita_score"]}äºº | 

å‚è€ƒãƒšãƒ¼ã‚¸

https://flamevalue.short-tips.info/{row["name"]}


{row.get("admin_comment") if row.get("admin_comment") else ""}
        """

    context = f"""
## ã“ã®è¨˜äº‹ã®èª¬æ˜

ã“ã®è¨˜äº‹ã¯<a href="https://flamevalue.short-tips.info/"> ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è»¢è·è©•ä¾¡ Flamevalue</a> ã®ã‚µã‚¤ãƒˆã‹ã‚‰å¼•ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€
ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª/ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã‚‚ã®ã§ã™ã€‚

ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª/ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è©•ä¾¡ã‚’ã€æ¬¡ã®5ã¤ã®è¦³ç‚¹ã‹ã‚‰ç‚¹æ•°åŒ–ã—ã¦ãŠã‚Šã¾ã™ã€‚
è»¢è·ã‚„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢æ¡ç”¨ã®éš›ã®ä¸€ã¤ã®å‚è€ƒã¾ã§ã«ã”æ´»ç”¨ä¸‹ã•ã„ã€‚

# ãƒ©ãƒ³ã‚­ãƒ³ã‚°

{"".join(map(lambda row:row_context(row),sorted(FLAMEWORKDICT, key= sort_function, reverse=True)[:15]))}

    """
    flamevalue_score_ranking_count = 0
    return context



def index(request):
    global FLAMEWORKDICT
    FLAMEWORKDICT = jsonDictionalyManager.generate_all_flameworkdict()
    if request.GET.get("refresh_all"):
        p = Process(target=refresh_all)
        p.start()
    compare_list = list( map( 
        lambda candidate_list:{
            "link" : "/compare.html?candidate=" + "&candidate=".join(candidate_list),
            "title":" vs ".join(candidate_list),
            "param":(list(filter(lambda param: param["name"] in candidate_list ,FLAMEWORKDICT)))
        }, COMPARE_STAGE_LIST
    ))
    COMPARE_STAGE_LIST_tmp = COMPARE_STAGE_LIST
    name = "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯"
    param = {
        "title" : "ã€Œå¹´å/æ¡ç”¨ä¼æ¥­ã€FlameValue ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è»¢è·è©•ä¾¡",
        "compare_list" : compare_list,
        "description" : f"ã€Œå¹´å/æ¡ç”¨ä¼æ¥­æƒ…å ±ã€ã€‚å°±è·ãƒ»è»¢è·å‰ã«{name}ã®åƒãç’°å¢ƒã€å¹´åãƒ»æ±‚äººæ•°ãªã©ã‚’ãƒªã‚µãƒ¼ãƒã€‚å°±è·ãƒ»è»¢è·ã®ãŸã‚ã®ã€Œ{name}ã€ã®ä¾¡å€¤åˆ†æãƒãƒ£ãƒ¼ãƒˆã€æ±‚äººæƒ…å ±ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æ²è¼‰ã€‚",
        "FLAMEWORKDICT" : sorted(FLAMEWORKDICT, key=lambda x: x["total_score"], reverse=True),
        "compare_stage_list" : list(map(lambda row: list(row), COMPARE_STAGE_LIST)) ,
        "img" : "https://github.com/kawadasatoshi/minegishirei/blob/main/flamevalue/flamevalue.png?raw=true"
    }
    return render(request, f"jobstatic_pages/index.html", param)

def sitemap(request):
    map(lambda row:"compare.html?candidate=" + "&candidate=".join(list(row)) ,COMPARE_STAGE_LIST)

    param = {
        "pop_page_list" : jsonDictionalyManager.generate_all_flameworkdict(),
        "candidate_endpoint_list" :  map(lambda row:"compare.html?candidate=" + "&candidate=".join(list(row)) ,COMPARE_STAGE_LIST)
    }
    return render(request, f"jobstatic_pages/sitemap.xml", param)

def robots(request):
    return render(request, f"robots.txt")

def reverse_index(request):
    return redirect("/")

def search(request):
    param = {
        "title" : "FlameValueå„ç¨®ãƒªãƒ³ã‚¯"
    }
    return render(request, f"jobstatic_pages/search.html", param)

def api_candidate(request):
    unfinished_title = request.GET.get("unfinished_title")
    sorted_flamework_list = list(map(lambda x: x["name"], sorted(FLAMEWORKDICT, key=lambda x: calc_distance(x["name"], unfinished_title))))
    json_dict = {
        "candidate" : sorted_flamework_list
    }
    json_str = json.dumps(json_dict, ensure_ascii=False, indent=2) 
    return HttpResponse(json_str)

import time
def refresh_all():
    global FLAMEWORKDICT
    jsonIO = JsonIO()
    for row in FLAMEWORKDICT:
        time.sleep(1)
        name = row["name"]
        try:
            param = build_param(name)
            jsonIO.write(param["name"],param)
            print("ã€reflashã€‘ : ", name)
        except:
            print("ã€reflash_missed!!!ã€‘ : ", name)


def reload_subprocess(name):
    jsonIO = JsonIO()
    param = build_param(name)
    jsonIO.write(param["name"],param)


def login(request):
    param = {}
    if "create_acount" in request.POST:
        if SQLiteLoginControl().create_acount(request):
            pass
        else:
            param = {
                "error_message" : "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            }
            return render(request, f"jobstatic_pages/login.html", param)
        request = get_deleted_all_session(request)
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆå¾Œ ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚Œã¦ã„ãªã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰
        # ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å…¥ã‚Œã‚‹
        user_info = SQLiteLoginControl().fetch_user_info_by_unhashed_password( request.POST.get("e_mail"), request.POST.get("unhashed_password"))
        request.session.update(user_info)
        return redirect("/")
    elif "login_acount" in request.POST:
        if SQLiteLoginControl().certification_by_unhashed_password(request.POST.get("e_mail") , request.POST.get("unhashed_password")):
            # ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å…¥ã‚Œã‚‹
            user_info = UserInfoCollector().fetch_user_fullinfo( request.POST.get("e_mail"))
            request.session.update(user_info)
            return index(request)
        else:
            return render(request, f"jobstatic_pages/login.html", param)
    elif "logout_acount" in request.POST:
        request = get_deleted_all_session(request)
        return redirect("/")
    return render(request, f"jobstatic_pages/login.html", param)


import statistics
def useradmin(request):
    param = {}
    if "update_acount" in request.POST:
        message_list = []
        if request.POST.get("unhashed_password") and SQLiteLoginControl().update_acount_password(request.POST.get("e_mail"), request.POST.get("unhashed_password")):
            user_info = SQLiteLoginControl().fetch_user_info_by_unhashed_password( request.POST.get("e_mail"), request.POST.get("unhashed_password"))
            request.session.update(user_info)
            message_list.append("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼šå®Œäº†")
        if request.POST.get("profile_image_url") and SQLiteProfileImage().replace(request.POST.get("e_mail"), request.POST.get("profile_image_url")):
            request.session["profile_image_url"] = SQLiteProfileImage().fetch(request.POST.get("e_mail"))["profile_image_url"]
            message_list.append("ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¤ãƒ¡ãƒ¼ã‚¸è¨­å®šï¼šå®Œäº†")
        if request.POST.get("e_mail") and SQLiteLoginControl().update_acount(request.POST.get("e_mail"), request.POST.get("username")):
            message_list.append("ãƒ¡ãƒ¼ãƒ«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼åè¨­å®šï¼šå®Œäº†")
        param.update({
            "message_list" : message_list
        })
    user_good_flameworks = UserInfoCollector().get_user_good_flameworks(request.session.get("e_mail"))
    user_good_flameworks_dict = list( filter(lambda row: row.get("name") in map(lambda user_good_flamework: user_good_flamework["FLAMEWORK_NAME"] ,user_good_flameworks), FLAMEWORKDICT))
    
    param.update({
        "users" : UserInfoCollector().get_users(),
        "user_good_flameworks" : user_good_flameworks,
        "user_good_flameworks_dict" : user_good_flameworks_dict,
        "average_money" : statistics.mean(map( lambda row : row["basic"]["money"], user_good_flameworks_dict) ),
        "average_overtime" : statistics.mean(map( lambda row : row["basic"]["overtime"], user_good_flameworks_dict) ),
        "average_count" : statistics.mean(map( lambda row : row["basic"]["count"], user_good_flameworks_dict) ),
        "average_remote" : statistics.mean(map( lambda row : row["basic"]["remote"], user_good_flameworks_dict) ),
        "average_score_overtime" : int( 20*statistics.mean(map( lambda row : row["score"]["overtime"], user_good_flameworks_dict)) ),
        "average_score_money" : int( 20*statistics.mean(map( lambda row : row["score"]["money"], user_good_flameworks_dict)) ),
        "average_score_count" : int( 20*statistics.mean(map( lambda row : row["score"]["count"], user_good_flameworks_dict)) ),
        "average_score_remote" : int( 20*statistics.mean(map( lambda row : row["score"]["remote"], user_good_flameworks_dict)) ),
    })
    return render(request, f"jobstatic_pages/profile.html", param)


def get_deleted_all_session(request):
    session_copy = {}
    for key, value in request.session.items():
        session_copy[key] = value
    for key, value in session_copy.items():
        del request.session[key]
    return request








def judge_certification_ok(request):
    e_mail = request.session.get("e_mail")
    hashed_password = request.session.get("hashed_password") 
    username = request.session.get("username")
    has_session_info = ("e_mail" in request.session) and ("hashed_password" in request.session)
    is_certification_ok = SQLiteLoginControl().certification_by_hashed_password(request.session.get("e_mail") , request.session.get("hashed_password", ""))
    return has_session_info and (is_certification_ok)





